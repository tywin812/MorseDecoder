{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e97f46b",
   "metadata": {},
   "source": [
    "## Preparing & loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c3b8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from functools import partial\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchaudio   \n",
    "from torchaudio.functional import edit_distance\n",
    "from torchaudio.models.decoder import ctc_decoder\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8260e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FILES_DIR = Path('/mnt/c/Study/Python/Morse/morse_dataset')\n",
    "CACHE_DIR = Path(\"/mnt/c/Study/Python/Morse/mel_cache\")\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "train_df = pd.read_csv('/mnt/c/Study/Python/Morse/train.csv')\n",
    "val_df = pd.read_csv('/mnt/c/Study/Python/Morse/val.csv')\n",
    "test_df = pd.read_csv('/mnt/c/Study/Python/Morse/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45674f86",
   "metadata": {},
   "source": [
    "Получение словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70fcfd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(words: pd.Series, blank: str = \"<blk>\") -> dict[int, str]:\n",
    "    \"\"\"\n",
    "    Строит словарь всех уникальных символов.\n",
    "    \"\"\"\n",
    "    vocab = {0: blank, 1: \"|\"}\n",
    "    all_chars = set(\"\".join(words.astype(str)))\n",
    "\n",
    "    for i, char in enumerate(sorted(all_chars), start=2):\n",
    "        vocab[i] = char\n",
    "\n",
    "    print(f\"Vocab is ready, size = {len(vocab)}\")\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a25aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab is ready, size = 46\n"
     ]
    }
   ],
   "source": [
    "full_vocab = get_vocab(train_df['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd64ed00",
   "metadata": {},
   "source": [
    "Tokenizer для перевода символов в индексы и наоборот"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45cc655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, vocab: Dict[int, str]):\n",
    "        self.index_char = vocab\n",
    "        self.char_index = {char: index for index, char in self.index_char.items()}\n",
    "\n",
    "    def __call__(\n",
    "        self, chars: Union[str, List[str]]\n",
    "    ) -> Union[List[int], List[List[int]]]:\n",
    "        \"\"\"\n",
    "        Преобразует строку или список строк в список индексов.\n",
    "        \"\"\"\n",
    "        if isinstance(chars, str):\n",
    "            return [self.char_index.get(char, -1) for char in chars]\n",
    "        elif isinstance(chars, list):\n",
    "            return [self.__call__(t) for t in chars]\n",
    "        else:\n",
    "            raise ValueError(\"Expected list or str\")\n",
    "\n",
    "    def decode(\n",
    "        self, indexs: Union[List[int], List[List[int]]]\n",
    "    ) -> Union[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Преобразует список индексов или список списков индексов обратно в строку(и).\n",
    "        \"\"\"\n",
    "        if isinstance(indexs, list):\n",
    "            if isinstance(indexs[0], list):\n",
    "                return [self.decode(i) for i in indexs]\n",
    "            else:\n",
    "                return \"\".join([self.index_char.get(idx, \"\") for idx in indexs])\n",
    "        else:\n",
    "            raise ValueError(\"Expected list or str\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05e7d55",
   "metadata": {},
   "source": [
    "Готовая функция для перевода выходов модели в конечный набор символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58956855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_to_tokens(\n",
    "    decoder: Callable,\n",
    "    model_output: torch.Tensor,\n",
    "    tokenizer: Callable,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Применяет декодер(beam_search) и tokenizer к выходу модели и возвращает расшифрованные строки.\n",
    "    \"\"\"\n",
    "\n",
    "    log_probs = nn.functional.log_softmax(model_output, dim=-1)\n",
    "    results = decoder(log_probs.contiguous())  # log_probs: [B, T, C]\n",
    "\n",
    "    decoded_sequences = []\n",
    "    for batch_result in results:\n",
    "        top_hypo = batch_result[0]\n",
    "        tokens = top_hypo.tokens.tolist()\n",
    "        decoded_sequence = tokenizer.decode(tokens)\n",
    "        decoded_sequence = decoded_sequence.strip(\"|\")\n",
    "        decoded_sequences.append(decoded_sequence)\n",
    "\n",
    "    return decoded_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312e1568",
   "metadata": {},
   "source": [
    "Адаптация nn.CTCLoss под нашу задачу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a34136fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_ctc(\n",
    "    model_output: torch.Tensor,  # Тензор [Batch, Time, Classes] - ожидается на device\n",
    "    targets: torch.Tensor,  # Тензор [sum(target_lengths)] - ожидается на CPU\n",
    "    target_lengths: torch.Tensor,  # Тензор [B] - ожидается на CPU\n",
    "    blank_id: int = 0,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Вычисляет CTC-лосс (Connectionist Temporal Classification) между выходом модели и целевыми метками.\n",
    "\n",
    "    \"\"\"\n",
    "    log_output = F.log_softmax(model_output, dim=-1)\n",
    "    log_output = log_output.transpose(0, 1)\n",
    "\n",
    "    output_time_dim = log_output.shape[0]  # T'\n",
    "    batch_size = log_output.shape[1]  # B\n",
    "\n",
    "    output_lengths = torch.full(\n",
    "        size=(batch_size,), fill_value=output_time_dim, dtype=torch.long, device=\"cpu\"\n",
    "    )\n",
    "    targets_cpu = targets.cpu()\n",
    "    target_lengths_cpu = target_lengths.cpu()\n",
    "\n",
    "    loss = nn.CTCLoss(blank=blank_id, reduction=\"mean\", zero_infinity=True)\n",
    "\n",
    "    batch_loss = loss( \n",
    "        log_output.float(), targets_cpu, output_lengths, target_lengths_cpu\n",
    "    )\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34309d8a",
   "metadata": {},
   "source": [
    "Класс Dataset, принимающий имена файлов, transform для предобработки этих файлов и tokenizer для подготовки target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b7bc854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Класс для загрузки и обработки датасета\n",
    "\n",
    "    Атрибуты:\n",
    "        X_filenames (pd.Series): Список путей к аудио файлам.\n",
    "        y_texts (Optional[pd.Series]): Список целевых меток (строки).\n",
    "        transform (Optional[Callable]): Функция для преобразования аудио файлов в признаки.\n",
    "        tokenizer (Optional[Callable[[str], list]]): Tokenizer для преобразования текста в индексы.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        X_filenames: pd.Series,\n",
    "        y_texts: Optional[pd.Series] = None,\n",
    "        transform: Optional[Callable] = None,\n",
    "        tokenizer: Optional[Callable[[str], list]] = None,\n",
    "    ):\n",
    "        self.X_filenames = X_filenames.reset_index(drop=True)\n",
    "        self.y_texts = y_texts.reset_index(drop=True) if y_texts is not None else None\n",
    "        self.transform = transform\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.X_filenames)\n",
    "\n",
    "    def __getitem__(self, idx) -> Dict[str, torch.Tensor]:\n",
    "        filename = self.X_filenames[idx]\n",
    "        mel_features = self.transform(filename)  # [C, T] ([n_mels, time])\n",
    "\n",
    "        item = {\"input\": torch.tensor(mel_features, dtype=torch.float)}\n",
    "\n",
    "        if self.y_texts is not None:\n",
    "            text = self.y_texts[idx]\n",
    "            if self.tokenizer:\n",
    "                target = self.tokenizer(text)\n",
    "            else:\n",
    "                raise ValueError(\"Tokenizer needs for target encoding\")\n",
    "            item[\"target_text\"] = text\n",
    "            item[\"target\"] = torch.tensor(target, dtype=torch.long)\n",
    "            item[\"target_length\"] = len(target)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd65d3bb",
   "metadata": {},
   "source": [
    "Функции для создания DataLoader с кастомным collate_fn для создания удобного batch при работе с CTCLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73254815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_collate(batch: List[Dict[str, torch.Tensor]]) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Функция для объединения элементов батча, с добавлением паддинга для последовательностей.\n",
    "    \"\"\"\n",
    "    inputs = [item[\"input\"].T for item in batch]  # [T, C]\n",
    "\n",
    "    padded_inputs = pad_sequence(inputs, batch_first=True)  # [B, max_T, C]\n",
    "    padded_inputs = padded_inputs.transpose(1, 2)  # [B, C, T]\n",
    "\n",
    "    collated = {\n",
    "        \"input\": padded_inputs,\n",
    "    }\n",
    "\n",
    "    if \"target\" in batch[0]:\n",
    "        targets = torch.cat([item[\"target\"] for item in batch], dim=0)\n",
    "        target_lengths = torch.tensor(\n",
    "            [item[\"target_length\"] for item in batch], dtype=torch.long\n",
    "        )\n",
    "        collated[\"target_text\"] = [item[\"target_text\"] for item in batch]\n",
    "        collated[\"target\"] = targets\n",
    "        collated[\"target_length\"] = target_lengths\n",
    "\n",
    "    return collated\n",
    "\n",
    "\n",
    "def data_loader(\n",
    "    dataset: torch.utils.data.Dataset,\n",
    "    batch_size: int,\n",
    "    shuffle: bool,\n",
    "    num_workers: int = 0,\n",
    "    drop_last: bool = True,\n",
    ") -> DataLoader:\n",
    "    \"\"\"\n",
    "    Функция для создания DataLoader с заданными параметрами.\n",
    "    \"\"\"\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=dataloader_collate,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=drop_last,\n",
    "        pin_memory=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87cda43",
   "metadata": {},
   "source": [
    "Основная функция для обучения модели и валидации результатов. <br>\n",
    "Для обучения используется CTC-loss. Валидация проводится с использованием beam-search декодирования, <br>\n",
    "после чего рассчитывается расстояние Левенштейна между предсказанным и истинным текстом.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad4649bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    ctc_loss: Callable,\n",
    "    epochs: int,\n",
    "    metric: Callable,\n",
    "    decoder: Callable,\n",
    "    tokenizer: Callable,\n",
    "    val_loader: Union[DataLoader, None] = None,\n",
    "    scheduler: Union[Callable, None] = None,\n",
    "    save_path: str = \"best_model.pt\",\n",
    ") -> Tuple[nn.Module, Dict[str, List]]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: Нейронная сеть для обучения.\n",
    "        train_loader: DataLoader для тренировочных данных.\n",
    "        optimizer: Оптимизатор для обновления параметров модели.\n",
    "        ctc_loss: Функция CTC-лосса.\n",
    "        epochs: Количество эпох обучения.\n",
    "        metric: Функция для оценки качества предсказаний (например, edit_distance).\n",
    "        decoder: Функция декодирования CTC-выхода в токены.\n",
    "        tokenizer: Функция токенизации текста.\n",
    "        val_loader: DataLoader для валидационных данных (опционально).\n",
    "        scheduler: Планировщик скорости обучения (опционально).\n",
    "        save_path: Путь для сохранения лучшей модели (по умолчанию \"best_model.pt\").\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - Trained model (nn.Module)\n",
    "        - Dictionary with metrics (\"train_loss\", \"val_loss\", \"val_metric\")\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model.to(device, non_blocking=True)\n",
    "    metrics = {\"train_loss\": [], \"val_loss\": [], \"val_metric\": []}\n",
    "    \n",
    "    best_val_metric = float(\"inf\")  \n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n Epoch {epoch + 1}/{epochs}\")\n",
    "        epoch_loss = []\n",
    "        model.train()\n",
    "        with tqdm(\n",
    "            train_loader, desc=\"Training\", total=len(train_loader), dynamic_ncols=True\n",
    "        ) as pbar:\n",
    "            for batch in pbar:\n",
    "                inputs = batch[\"input\"].to(device, non_blocking=True)  # (B, C, T)\n",
    "                targets = batch[\"target\"]  # (sum_target_len,)\n",
    "                target_lengths = batch[\"target_length\"]  # (B,)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output = model(inputs)\n",
    "                loss = ctc_loss(output, targets, target_lengths)\n",
    "\n",
    "                loss.backward()\n",
    "                clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                epoch_loss.append(loss.item())\n",
    "\n",
    "        avg_epoch_loss = np.mean(epoch_loss)\n",
    "        metrics[\"train_loss\"].append(avg_epoch_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} with loss = {avg_epoch_loss:.4f}\")\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            print(f\"Learning_rate = {scheduler.get_last_lr()}\")\n",
    "\n",
    "        if val_loader is not None:\n",
    "            model.eval()\n",
    "            epoch_val_metrics = []\n",
    "            epoch_val_losses = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(\n",
    "                    val_loader, desc=f\"Validation Epoch {epoch + 1}\", leave=False\n",
    "                ):\n",
    "                    inputs = batch[\"input\"].to(device, non_blocking=True)  # (B, C, T)\n",
    "                    target_text = batch[\"target_text\"]\n",
    "                    targets = batch[\"target\"]  # (sum_target_len,)\n",
    "                    target_lengths = batch[\"target_length\"]  # (B,)\n",
    "                    predictions = model(inputs)\n",
    "                    \n",
    "                    val_loss = ctc_loss(predictions, targets, target_lengths)\n",
    "                    epoch_val_losses.append(val_loss.item())\n",
    "\n",
    "                    emissions = predictions.detach().cpu().float()\n",
    "\n",
    "                    tokens_output = decoding_to_tokens(decoder, emissions, tokenizer)\n",
    "                    batch_val_metrics = [\n",
    "                        metric(pred, gt) for pred, gt in zip(tokens_output, target_text)\n",
    "                    ]\n",
    "                    epoch_val_metrics.append(np.mean(batch_val_metrics))\n",
    "\n",
    "            avg_epoch_val_metrics = np.mean(epoch_val_metrics)\n",
    "            avg_epoch_val_loss = np.mean(epoch_val_losses)\n",
    "            metrics[\"val_loss\"].append(avg_epoch_val_loss)\n",
    "            metrics[\"val_metric\"].append(avg_epoch_val_metrics)\n",
    "            print(f\"Val Loss={avg_epoch_val_loss:.4f}, Val Metric={avg_epoch_val_metrics:.4f}\")\n",
    "            \n",
    "            if avg_epoch_val_metrics < best_val_metric:\n",
    "                best_val_metric = avg_epoch_val_metrics\n",
    "                best_model_state = model.state_dict()\n",
    "                torch.save(best_model_state, save_path)\n",
    "                print(f\"Saved best model with Val Metric={best_val_metric:.4f} at {save_path}\")\n",
    "\n",
    "        else:\n",
    "            metrics[\"val_loss\"].append(None)\n",
    "            metrics[\"val_metric\"].append(None)\n",
    "\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8481d236",
   "metadata": {},
   "source": [
    "Блоки для создания модели - сверточный блок и LSTM-блок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eff4c548",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Свёрточный блок с нормализацией и активацией ReLU.\n",
    "\n",
    "    Включает свёртку (Conv1d), слой нормализации (LayerNorm) и активацию ReLU.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int,\n",
    "        padding: int,\n",
    "        stride: int = 1,\n",
    "        groups: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            padding=padding,\n",
    "            stride=stride,\n",
    "            groups=groups,\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x.transpose(1, 2)).transpose(1, 2)\n",
    "        return self.relu(x)\n",
    "\n",
    "\n",
    "class LstmBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Блок LSTM с нормализацией и dropout.\n",
    "\n",
    "    Включает двустороннюю LSTM (2 слоя), слой нормализации (LayerNorm) и слой dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(hidden_size * 2)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.drop(self.norm(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cd89cd",
   "metadata": {},
   "source": [
    "Инициализация начальных весов модели в зависимости от блока."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9357ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(module: nn.Module) -> None:\n",
    "    \"\"\"\n",
    "    Инициализация весов для различных типов слоёв.\n",
    "    \"\"\"\n",
    "    if isinstance(module, nn.Conv1d):\n",
    "        init.kaiming_normal_(module.weight, nonlinearity=\"relu\")\n",
    "        if module.bias is not None:\n",
    "            init.constant_(module.bias, 0)\n",
    "\n",
    "    elif isinstance(module, nn.Linear):\n",
    "        init.xavier_uniform_(module.weight)\n",
    "        if module.bias is not None:\n",
    "            init.constant_(module.bias, 0)\n",
    "\n",
    "    elif isinstance(module, nn.LSTM):\n",
    "        for name, param in module.named_parameters():\n",
    "            if \"weight_ih\" in name:\n",
    "                init.xavier_uniform_(param)\n",
    "            elif \"weight_hh\" in name:\n",
    "                init.orthogonal_(param)\n",
    "            elif \"bias\" in name:\n",
    "                init.constant_(param, 0)\n",
    "\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        if module.elementwise_affine:\n",
    "            init.constant_(module.weight, 1.0)\n",
    "            init.constant_(module.bias, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2752ec45",
   "metadata": {},
   "source": [
    "Отрисовка словаря с метриками, полученного после функции train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "930f70a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(\n",
    "    metrics_dict: dict,\n",
    "    title: str = \"Model Metrics\",\n",
    "    xlabel: str = \"Epochs\",\n",
    "    ylabel: str = \"Metric Value\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Функция для отображения метрик в виде графиков.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    epochs = range(1, len(list(metrics_dict.values())[0]) + 1)\n",
    "\n",
    "    for metric_name, metric_values in metrics_dict.items():\n",
    "        if metric_values:\n",
    "            plt.plot(epochs, metric_values, label=metric_name)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79356fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_blackmel_cached(\n",
    "    file_name: str,\n",
    "    audio_files_dir: Path,\n",
    "    cache_dir: Path,\n",
    "    overwrite: bool = False,\n",
    ") -> np.ndarray:\n",
    "    cache_path = cache_dir / (file_name.replace(\".wav\", \".npy\"))\n",
    "\n",
    "    if cache_path.exists() and not overwrite:\n",
    "        return np.load(cache_path)\n",
    "\n",
    "    waveform, sr = torchaudio.load(audio_files_dir / file_name)\n",
    "\n",
    "    mel = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sr, n_fft=512, hop_length=128, n_mels=64\n",
    "    )(waveform)\n",
    "    boost_mel = mel**5\n",
    "    boost_mel = boost_mel / boost_mel.max()\n",
    "    mel_db = torchaudio.transforms.AmplitudeToDB(top_db=64)(boost_mel)\n",
    "    mel_db = mel_db.squeeze(0).cpu().numpy()\n",
    "\n",
    "    peak = np.argmax(mel_db.mean(axis=1))\n",
    "    start = max(peak - 10, 0)\n",
    "    end = min(peak + 10, mel_db.shape[0])\n",
    "    fresh_mel = mel_db[start:end]\n",
    "\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    np.save(cache_path, fresh_mel)\n",
    "    return fresh_mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc92732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorseDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: Tuple[int, int],\n",
    "        kernel_chanel: int,\n",
    "        conv_out_size: int,\n",
    "        vocab_size: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_part = nn.Sequential(\n",
    "            ConvBlock(\n",
    "                in_channels=input_size[0],\n",
    "                out_channels=kernel_chanel,\n",
    "                kernel_size=5,\n",
    "                padding=2,\n",
    "                stride=2,\n",
    "            ),\n",
    "            ConvBlock(\n",
    "                in_channels=kernel_chanel,\n",
    "                out_channels=conv_out_size,\n",
    "                kernel_size=4,\n",
    "                padding=0,\n",
    "                stride=2,\n",
    "            ),\n",
    "            ConvBlock(\n",
    "                in_channels=conv_out_size,\n",
    "                out_channels=conv_out_size,\n",
    "                kernel_size=3,\n",
    "                padding=0,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.rnn_part = nn.Sequential(\n",
    "            LstmBlock(input_size=conv_out_size, hidden_size=64, dropout=0.4),\n",
    "        )\n",
    "\n",
    "        self.clf = nn.Linear(\n",
    "            in_features=64 * 2,\n",
    "            out_features=vocab_size,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_part(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.rnn_part(x)\n",
    "        return self.clf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2130886",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search_decoder = ctc_decoder(\n",
    "    lexicon=None,\n",
    "    tokens=list(full_vocab.values()),\n",
    "    beam_size=3,\n",
    "    nbest=1,\n",
    "    blank_token=\"<blk>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ad14996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<blk>', 1: '|', 2: ' ', 3: '#', 4: '0', 5: '1', 6: '2', 7: '3', 8: '4', 9: '5', 10: '6', 11: '7', 12: '8', 13: '9', 14: 'А', 15: 'Б', 16: 'В', 17: 'Г', 18: 'Д', 19: 'Е', 20: 'Ж', 21: 'З', 22: 'И', 23: 'Й', 24: 'К', 25: 'Л', 26: 'М', 27: 'Н', 28: 'О', 29: 'П', 30: 'Р', 31: 'С', 32: 'Т', 33: 'У', 34: 'Ф', 35: 'Х', 36: 'Ц', 37: 'Ч', 38: 'Ш', 39: 'Щ', 40: 'Ъ', 41: 'Ы', 42: 'Ь', 43: 'Э', 44: 'Ю', 45: 'Я'}\n",
      "{'<blk>': 0, '|': 1, ' ': 2, '#': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, 'А': 14, 'Б': 15, 'В': 16, 'Г': 17, 'Д': 18, 'Е': 19, 'Ж': 20, 'З': 21, 'И': 22, 'Й': 23, 'К': 24, 'Л': 25, 'М': 26, 'Н': 27, 'О': 28, 'П': 29, 'Р': 30, 'С': 31, 'Т': 32, 'У': 33, 'Ф': 34, 'Х': 35, 'Ц': 36, 'Ч': 37, 'Ш': 38, 'Щ': 39, 'Ъ': 40, 'Ы': 41, 'Ь': 42, 'Э': 43, 'Ю': 44, 'Я': 45}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(vocab=full_vocab)\n",
    "\n",
    "print(tokenizer.index_char)\n",
    "print(tokenizer.char_index)\n",
    "\n",
    "transform = partial(\n",
    "    path_to_blackmel_cached,\n",
    "    audio_files_dir=AUDIO_FILES_DIR,\n",
    "    cache_dir=CACHE_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e640a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MorseDataset(\n",
    "    X_filenames=train_df['id'],\n",
    "    y_texts=train_df['message'],\n",
    "    transform=transform,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "train_loader = data_loader(\n",
    "    train_dataset, batch_size=64, shuffle=True, drop_last=True, num_workers=2\n",
    ")\n",
    "\n",
    "val_dataset = MorseDataset(\n",
    "    X_filenames=val_df['id'], y_texts=val_df['message'], transform=transform, tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "val_loader = data_loader(\n",
    "    val_dataset, batch_size=64, shuffle=False, drop_last=True, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c23d3d",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7430cddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MorseDecoder(\n",
       "  (conv_part): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (conv): Conv1d(20, 32, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv): Conv1d(32, 64, kernel_size=(4,), stride=(2,))\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (rnn_part): Sequential(\n",
       "    (0): LstmBlock(\n",
       "      (lstm): LSTM(64, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop): Dropout(p=0.4, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (clf): Linear(in_features=128, out_features=46, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_blackmel_model = MorseDecoder(\n",
    "    input_size=[20, 501],\n",
    "    kernel_chanel=32,\n",
    "    conv_out_size=64,\n",
    "    vocab_size=len(full_vocab),\n",
    ")\n",
    "torch.manual_seed(SEED)\n",
    "cnn_blackmel_model.apply(init_weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn_blackmel_model.parameters(), lr=0.005)\n",
    "\n",
    "step_lr = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "cnn_blackmel_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b803a789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      " Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [13:01<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss = 4.0412\n",
      "Learning_rate = [0.005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0846, Val Metric=8.8991\n",
      "Saved best model with Val Metric=8.8991 at best_model.pt\n",
      "\n",
      " Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:57<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 with loss = 4.0256\n",
      "Learning_rate = [0.005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0550, Val Metric=8.8991\n",
      "\n",
      " Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:55<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 with loss = 4.0197\n",
      "Learning_rate = [0.005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0764, Val Metric=8.8991\n",
      "\n",
      " Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:55<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 with loss = 4.0129\n",
      "Learning_rate = [0.005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0566, Val Metric=8.7293\n",
      "Saved best model with Val Metric=8.7293 at best_model.pt\n",
      "\n",
      " Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:55<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 with loss = 4.0056\n",
      "Learning_rate = [0.005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0629, Val Metric=8.5887\n",
      "Saved best model with Val Metric=8.5887 at best_model.pt\n",
      "\n",
      " Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:55<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 with loss = 4.0032\n",
      "Learning_rate = [0.005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0248, Val Metric=8.6997\n",
      "\n",
      " Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:54<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 with loss = 4.0027\n",
      "Learning_rate = [0.005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0373, Val Metric=8.6039\n",
      "\n",
      " Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:54<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 with loss = 4.0017\n",
      "Learning_rate = [0.005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0373, Val Metric=8.6009\n",
      "\n",
      " Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:55<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 with loss = 4.0020\n",
      "Learning_rate = [0.005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0370, Val Metric=8.6155\n",
      "\n",
      " Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:54<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 with loss = 4.0015\n",
      "Learning_rate = [0.0025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0389, Val Metric=8.6070\n",
      "\n",
      " Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:54<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 with loss = 3.9988\n",
      "Learning_rate = [0.0025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0231, Val Metric=8.6036\n",
      "\n",
      " Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:54<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 with loss = 3.9985\n",
      "Learning_rate = [0.0025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0277, Val Metric=8.7130\n",
      "\n",
      " Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:54<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 with loss = 3.9985\n",
      "Learning_rate = [0.0025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0147, Val Metric=8.7065\n",
      "\n",
      " Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:54<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 with loss = 3.9983\n",
      "Learning_rate = [0.0025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0138, Val Metric=8.7211\n",
      "\n",
      " Epoch 15/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:54<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 with loss = 3.9987\n",
      "Learning_rate = [0.0025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0194, Val Metric=8.5897\n",
      "\n",
      " Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:54<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 with loss = 3.9987\n",
      "Learning_rate = [0.0025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0075, Val Metric=8.6192\n",
      "\n",
      " Epoch 17/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:54<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 with loss = 3.9984\n",
      "Learning_rate = [0.0025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0027, Val Metric=8.5890\n",
      "\n",
      " Epoch 18/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:54<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 with loss = 3.9982\n",
      "Learning_rate = [0.0025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0138, Val Metric=8.5893\n",
      "\n",
      " Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 421/421 [01:54<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 with loss = 3.9985\n",
      "Learning_rate = [0.0025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss=4.0142, Val Metric=8.7048\n",
      "\n",
      " Epoch 20/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%|████████▏ | 344/421 [01:33<00:21,  3.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m cnn_blackmel_model, cnn_blackmel_metrics = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcnn_blackmel_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mctc_loss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_ctc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43medit_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeam_search_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, optimizer, ctc_loss, epochs, metric, decoder, tokenizer, val_loader, scheduler, save_path)\u001b[39m\n\u001b[32m     44\u001b[39m model.train()\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[32m     46\u001b[39m     train_loader, desc=\u001b[33m\"\u001b[39m\u001b[33mTraining\u001b[39m\u001b[33m\"\u001b[39m, total=\u001b[38;5;28mlen\u001b[39m(train_loader), dynamic_ncols=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     47\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (B, C, T)\u001b[39;49;00m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtarget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (sum_target_len,)\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mMorseDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx) -> Dict[\u001b[38;5;28mstr\u001b[39m, torch.Tensor]:\n\u001b[32m     28\u001b[39m     filename = \u001b[38;5;28mself\u001b[39m.X_filenames[idx]\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     mel_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [C, T] ([n_mels, time])\u001b[39;00m\n\u001b[32m     31\u001b[39m     item = {\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: torch.tensor(mel_features, dtype=torch.float)}\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.y_texts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mpath_to_blackmel_cached\u001b[39m\u001b[34m(file_name, audio_files_dir, cache_dir, overwrite)\u001b[39m\n\u001b[32m      7\u001b[39m cache_path = cache_dir / (file_name.replace(\u001b[33m\"\u001b[39m\u001b[33m.wav\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.npy\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_path.exists() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m waveform, sr = torchaudio.load(audio_files_dir / file_name)\n\u001b[32m     14\u001b[39m mel = torchaudio.transforms.MelSpectrogram(\n\u001b[32m     15\u001b[39m     sample_rate=sr, n_fft=\u001b[32m512\u001b[39m, hop_length=\u001b[32m128\u001b[39m, n_mels=\u001b[32m64\u001b[39m\n\u001b[32m     16\u001b[39m )(waveform)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/numpy/lib/npyio.py:456\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    453\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m.open_memmap(file, mode=mmap_mode,\n\u001b[32m    454\u001b[39m                                   max_header_size=max_header_size)\n\u001b[32m    455\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    460\u001b[39m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[32m    461\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/numpy/lib/format.py:809\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    806\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[32m    808\u001b[39m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m809\u001b[39m         array = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    810\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    811\u001b[39m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[32m    812\u001b[39m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    820\u001b[39m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[32m    821\u001b[39m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[32m    822\u001b[39m         array = numpy.ndarray(count, dtype=dtype)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "cnn_blackmel_model, cnn_blackmel_metrics = train_model(\n",
    "    model=cnn_blackmel_model,\n",
    "    train_loader=train_loader,\n",
    "    optimizer=optimizer,\n",
    "    ctc_loss=loss_ctc,\n",
    "    epochs=40,\n",
    "    metric=edit_distance,\n",
    "    decoder=beam_search_decoder,\n",
    "    tokenizer=tokenizer,\n",
    "    val_loader=val_loader,\n",
    "    scheduler=step_lr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da94958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(\n",
    "    model: nn.Module,\n",
    "    test_paths: pd.Series,\n",
    "    tokenizer: Tokenizer,\n",
    "    decoder: Callable,\n",
    "    batch_size: int = 32,\n",
    "    device: Optional[torch.device] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        model (nn.Module): Обученная модель для предсказаний.\n",
    "        test_paths (pd.Series): Имена тестовых аудиофайлов.\n",
    "        tokenizer (Tokenizer): Tokenizer для декодирования индексов.\n",
    "        decoder(Callable): Декодер для преобразования выходов модели в индексы словаря.\n",
    "        batch_size (int): Размер батча для DataLoader.\n",
    "        device (torch.device): Устройство (CPU или CUDA), на котором будет происходить вычисление.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame с декодированными предсказаниями.\n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    test_dataset = MorseDataset(\n",
    "        X_filenames=test_paths, transform=transform, tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    test_loader = data_loader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, drop_last=False\n",
    "    )\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(test_loader, desc=\"Predicting\", total=len(test_loader)) as pbar:\n",
    "            for batch in pbar:\n",
    "                inputs = batch[\"input\"].to(device)  # [B, C, T]\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                decoded_preds = decoding_to_tokens(decoder, outputs, tokenizer)\n",
    "\n",
    "                predictions.extend(decoded_preds)\n",
    "\n",
    "                pbar.set_postfix({\"Predictions\": len(predictions)})\n",
    "\n",
    "    return pd.DataFrame({\"id\": test_paths, \"message\": predictions})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
